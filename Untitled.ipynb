{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715522c1-1715-4899-b965-1ec0145af7c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0f3232-c4d0-451b-b5a9-8f1296bb3f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as korean_nlq_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "# Sample data (same as before)\n",
    "pdt_list = {\n",
    "    \"phone_model\": [\"핸드폰\",\"Samsung S24\", \"Galaxy S24\", \"S24\", \"iPhone\", \"iPhone 16\", \"Apple iPhone 15\",\"phone\",\"galaxy\", \"samsung galaxy\", \"galaxy f23\", \n",
    "                    \"m14 5g\",\"flip 6\", \"galaxy z fold\", \"삼성 S24\", \"갤럭시 S24\", \"S24\", \"아이폰\", \"아이폰 16\", \"애플 아이폰 15\", \"폰\", \"갤럭시\", \"삼성 갤럭시\",\n",
    "                    \"갤럭시 F23\", \"M14 5G\", \"플립 6\", \"갤럭시 Z 폴드\",\"Galaxy Tab S9 Ultra\", \"갤럭시 탭 S9 FE+\", \"샤오미 패드 6\", \"Lenovo Tab P12 Pro\"],\n",
    "    \"phone_feature\": [\"8GB RAM\", \"128GB Storage\", \"50MP Triple Rear Camera\", \"32MP Front Camera\", \"6.7 AMOLED Display\", \"120Hz\", \"5000mAh Battery\", \n",
    "                      \"67W Fast Charging\", \"Snapdragon 8 Gen 2 Processor\", \"Android 14 OS\", \"5G\", \"Bluetooth Connectivity\", \"128GB 저장공간\", \n",
    "                      \"50MP 트리플 후면 카메라\", \"32MP 전면 카메라\", \"6.7 AMOLED 디스플레이\", \"5000mAh 배터리\", \"67W 고속 충전\", \"Snapdragon 8 Gen 2 프로세서\", \n",
    "                      \"Bluetooth 연결\",\"SSD\"],\n",
    "    \"laptop_model\": [\"laptop\", \"랩탑\",\"맥북 에어\", \"Dell XPS\", \"HP Spectre\", \"Lenovo Yoga\",\"Galaxy Book3 Pro 360\", \"갤럭시 북3 프로 360\",\"Galaxy Book3 Ultra\",\"갤럭시 북3 울트라\",\n",
    "                     \"LG 그램 17\",\"MacBook Air M2\",\"맥북 에어 M2\"],\n",
    "    \"laptop_feature\": [\"32GB RAM\",\"16GB DDR5 RAM\",\"512GB SSD Storage\",\"Intel Core i7 13th Gen Processor\",\"15.6 FHD IPS Display, 144Hz\",\n",
    "                       \"NVIDIA RTX 4060 8GB GPU\",\"Windows 11 Home OS\",\"Bluetooth 5.2 Connectivity\",\"75Wh Battery with 100W USB-C Charging\",\"16GB DDR5 RAM\",\n",
    "                       \"512GB SSD 스토리지\", \"Intel Core i7 13세대 프로세서\", \"15.6 FHD IPS 디스플레이, 144Hz\",\"NVIDIA RTX 4060 8GB GPU\", \"Windows 11 Home OS\", \n",
    "                       \"Bluetooth 5.2 연결\", \"100W USB-C 충전이 가능한 75Wh 배터리\"]\n",
    "}\n",
    "pdt_gen = [\"phone\",\"screen\",\"camera\",\"display\",\"tv\",\"ac\",\"fridge\",\"전화기\", \"화면\", \"카메라\", \"디스플레이\", \"에어컨\", \"냉장고\"]\n",
    "quality = [\"최고\", \"저렴한\", \"인기\"]\n",
    "price = [\"20만 원\", \"$100K\", \"50만 원 이하\", \"70만 원 이상\"]\n",
    "verb_1 = [\"작동 안 함\", \"지원 안 됨\", \"충돌\", \"발열\"]\n",
    "verb_2 = [\"설치\", \"수리\", \"교체\"]\n",
    "samsung_service = [\"Samsung Health\", \"Samsung Dex\", \"Samsung Pay\"]\n",
    "\n",
    "# Korean Templates\n",
    "templates_kr = {\n",
    "    \"NLQ\": [\n",
    "        \"{phone_model} 모델 중 {phone_feature} 있는 제품 추천해줘.\",\n",
    "        \"{price} 이하 {phone_model} 있어?\",\n",
    "        \"{laptop_model} 중에서 {laptop_feature} 지원하는 거 찾아줘.\",\n",
    "        \"{phone_model} 중에서 {phone_feature}가 있는 휴대폰이 어느 것인지 알려주세요.\",\n",
    "        \"{phone_model} 어떤 게 {quality}야?\",\n",
    "        \"{phone_model} 중에 {verb_1} 문제 없는 제품은?\",\n",
    "        \"{laptop_model} 사려는데 {laptop_feature} 꼭 필요해.\",\n",
    "        \"{phone_model} {phone_feature} 있는 거 찾아줘.\",\n",
    "        \"{phone_model} 중에서 {price} 정도면 뭐 살 수 있어?\",\n",
    "        \"{phone_model} 중에 {samsung_service} 되는 모델은?\",\n",
    "        \"{phone_model} 중 {phone_feature} 있는 거 뭐가 좋아?\",\n",
    "        \"{phone_model} 중에서 {price} 이하 제품 추천해줘.\",\n",
    "        \"{laptop_model} {quality} 제품 추천해줘.\",\n",
    "        \"{phone_model} 쓰는데 {verb_1} 문제 생김. 대안 있어?\",\n",
    "        \"{phone_model} 중에 {phone_feature} + {price}인 것 있어?\",\n",
    "        \"{phone_model} 중에 {phone_feature} 괜찮은 거 있어?\"\n",
    "        \"{laptop_model} 중에서 {price} 이하로 살 수 있는 거 추천해줘.\"\n",
    "        \"{phone_model} {phone_feature} 지원하는 모델 중 {quality} 제품은?\"\n",
    "        \"{phone_model} 중에서 {samsung_service} 쓸 수 있는 게 뭐야?\"\n",
    "        \"{phone_model} 중에 {verb_1} 문제 자주 있는 거 알려줘.\"\n",
    "        \"{laptop_model} 살 건데 {price}대에서 괜찮은 거 있어?\"\n",
    "        \"{phone_model} 중에 {quality} 태블릿 추천해줘.\"\n",
    "        \"{phone_model} 중에서 {phone_feature} 있는 모델 뭐 있어?\"\n",
    "        \"{laptop_model} 중 {laptop_feature} 빠른 모델 있을까?\"\n",
    "        \"{phone_model} 쓰고 싶은데 {phone_feature} 꼭 있는 거 찾아줘.\",\n",
    "        \"{phone_model} 구매혜택\",\n",
    "        \"{pdt_gen} 설치\",\n",
    "        \"{pdt_gen} {verb_2} 비용\"\n",
    "    ],\n",
    "    \"KH\": [\n",
    "        \"{phone_model} {phone_feature} {price}\",\n",
    "        \"{laptop_model} {laptop_feature}\",\n",
    "        \"{phone_model} {phone_feature}\",\n",
    "        \"{phone_model} {phone_feature}\",\n",
    "        \"{phone_model} {price}\",\n",
    "        \"{laptop_model}\",\n",
    "        \"{phone_model} {phone_feature} {price}\",\n",
    "        \"{phone_feature}\",\n",
    "        \"{laptop_model} {price} {laptop_feature}\",\n",
    "        \"{phone_model} {phone_feature}\",\n",
    "        \"{phone_model} 를 사다\",\n",
    "        \"{laptop_model} 를 사다\",\n",
    "        \"{phone_model}\",\n",
    "        \"{pdt_gen}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Helper to pick a random element from a category\n",
    "def get_random(category):\n",
    "    if category in pdt_list:\n",
    "        return random.choice(pdt_list[category])\n",
    "    elif category == \"quality\":\n",
    "        return random.choice(quality)\n",
    "    elif category == \"price\":\n",
    "        return random.choice(price)\n",
    "    elif category == \"verb_1\":\n",
    "        return random.choice(verb_1)\n",
    "    elif category == \"samsung_service\":\n",
    "        return random.choice(samsung_service)\n",
    "    elif category == \"verb_2\":\n",
    "        return random.choice(verb_2)\n",
    "    return \"\"\n",
    "\n",
    "# Function to generate N records\n",
    "def generate_korean_nlq_records(n_records=10000):\n",
    "    records = []\n",
    "    half = n_records // 2\n",
    "    for _ in range(half):\n",
    "        template = random.choice(templates_kr[\"NLQ\"])\n",
    "        sentence = template.format(\n",
    "            phone_model=get_random(\"phone_model\"),\n",
    "            phone_feature=get_random(\"phone_feature\"),\n",
    "            laptop_model=get_random(\"laptop_model\"),\n",
    "            laptop_feature=get_random(\"laptop_feature\"),\n",
    "            price=get_random(\"price\"),\n",
    "            quality=get_random(\"quality\"),\n",
    "            verb_1=get_random(\"verb_1\"),\n",
    "            samsung_service=get_random(\"samsung_service\"),\n",
    "            verb_2 =get_random(\"verb_2\"),\n",
    "            pdt_gen = get_random(\"pdt_gen\")\n",
    "        )\n",
    "        records.append([\"NLQ\", sentence])\n",
    "    for _ in range(n_records - half):\n",
    "        template = random.choice(templates_kr[\"KH\"])\n",
    "        sentence = template.format(\n",
    "            phone_model=get_random(\"phone_model\"),\n",
    "            phone_feature=get_random(\"phone_feature\"),\n",
    "            laptop_model=get_random(\"laptop_model\"),\n",
    "            laptop_feature=get_random(\"laptop_feature\"),\n",
    "            price=get_random(\"price\"),\n",
    "            quality=get_random(\"quality\"),\n",
    "            verb_1=get_random(\"verb_1\"),\n",
    "            samsung_service=get_random(\"samsung_service\"),\n",
    "            pdt_gen = get_random(\"pdt_gen\")\n",
    "        )\n",
    "        records.append([\"KH\", sentence])\n",
    "    return records\n",
    "\n",
    "# Generate 20 sample records\n",
    "sample_korean_nlq = generate_korean_nlq_records(20000)\n",
    "df = pd.DataFrame(sample_korean_nlq, columns=[\"label\", \"query\"])\n",
    "df.to_csv(\"korean_training_dataset_20250406-0109.csv\", index=False)\n",
    "print(\"Saved as korean_nlq_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d746de27-22ab-454f-902e-43001cd4e3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank rows removed. Cleaned data saved as 'cleaned_file.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"korean_training_dataset_20250406-0109.csv\")\n",
    "\n",
    "# Drop rows with any blank (NaN) values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Optional: Save the cleaned data back to a new CSV\n",
    "df_cleaned.to_csv(\"korean_training_dataset_20250406-0240.csv\", index=False)\n",
    "\n",
    "print(\"Blank rows removed. Cleaned data saved as 'cleaned_file.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107dbbe-d660-4ecd-8734-48567524516e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37600449-ee1b-4f8e-9a5e-20a6a1d6f0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: NVIDIA GeForce RTX 2050\n",
      "2025-04-06 02:49:41,890 - Use pytorch device_name: cuda:0\n",
      "2025-04-06 02:49:41,890 - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dc34a0f4304a5caa2e0963ba998975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molla\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\molla\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20498796c4fd40fea7c8856399622cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c0d16668494df8bdfbe453c3003cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726531a069804ab5b7ab619bbd51298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42476d0e88df42b591271afbf21c43a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f5b9f9b56f45ed9d938deb77c30337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbe53d565844a73a4e96305d0405242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6c9684ce2a4d7aafa8044a8e27dd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc49ffd8880b461b994eeebc2d51baed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1756d95f28664b9c82af2d090a16fbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-06 02:50:52,471 - Softmax loss: #Vectors concatenated: 3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mSoftmaxLoss(model\u001b[38;5;241m=\u001b[39mmodel, sentence_embedding_dimension\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_sentence_embedding_dimension(), num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Validation evaluator\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m BinaryClassificationEvaluator\u001b[38;5;241m.\u001b[39mfrom_input_examples(val_samples, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval-eval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Fine-tune\u001b[39;00m\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     50\u001b[0m     train_objectives\u001b[38;5;241m=\u001b[39m[(train_dataloader, train_loss)],\n\u001b[0;32m     51\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     use_amp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Use automatic mixed precision if available\u001b[39;00m\n\u001b[0;32m     57\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\evaluation\\BinaryClassificationEvaluator.py:143\u001b[0m, in \u001b[0;36mBinaryClassificationEvaluator.from_input_examples\u001b[1;34m(cls, examples, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[0;32m    142\u001b[0m     sentences1\u001b[38;5;241m.\u001b[39mappend(example\u001b[38;5;241m.\u001b[39mtexts[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 143\u001b[0m     sentences2\u001b[38;5;241m.\u001b[39mappend(example\u001b[38;5;241m.\u001b[39mtexts[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    144\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(example\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(sentences1, sentences2, scores, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models, evaluation, LoggingHandler\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "import logging\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "print(\"Using device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO, handlers=[LoggingHandler()])\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "MODEL_SAVE_PATH = \"output/nlq_classifier\"\n",
    "DATA_PATH = \"korean_training_dataset_20250406-0240.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "\n",
    "# Convert label: 'KH' → 0, 'NLQ' → 1\n",
    "df['label'] = df['label'].map({'KH': 0, 'NLQ': 1})\n",
    "\n",
    "# Split dataset\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(df) * train_ratio)\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:]\n",
    "\n",
    "# Convert to InputExamples\n",
    "train_samples = [InputExample(texts=[row['query']], label=float(row['label'])) for _, row in train_df.iterrows()]\n",
    "val_samples = [InputExample(texts=[row['query']], label=float(row['label'])) for _, row in val_df.iterrows()]\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Define loss\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=2)\n",
    "\n",
    "# Validation evaluator\n",
    "evaluator = BinaryClassificationEvaluator.from_input_examples(val_samples, name='val-eval')\n",
    "\n",
    "# Fine-tune\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=EPOCHS,\n",
    "    evaluation_steps=500,\n",
    "    save_best_model=True,\n",
    "    output_path=MODEL_SAVE_PATH,\n",
    "    use_amp=True  # Use automatic mixed precision if available\n",
    ")\n",
    "\n",
    "print(f\"✅ Model saved to: {MODEL_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cf3cd16-6979-4d43-9244-884b439f3894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.26.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\molla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\molla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\molla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\molla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\molla\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\molla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d53ac-d57f-476c-90f9-2fe6c9e4cc88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
