{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f4f2bc-0934-4449-ad04-98eaf91b7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load medium English model\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac9779e5-9997-406f-acb8-a1751e1a307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token      Dep        Head       POS        Children\n",
      "--------------------------------------------------\n",
      "case       ROOT       case       NOUN       ['for']\n",
      "for        prep       case       ADP        ['iphone']\n",
      "iphone     pobj       for        NOUN       []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cc51818b96ee48a297ee196a5ce37471-0\" class=\"displacy\" width=\"575\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">case</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">iphone</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc51818b96ee48a297ee196a5ce37471-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc51818b96ee48a297ee196a5ce37471-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M225.0,91.5 L233.0,79.5 217.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cc51818b96ee48a297ee196a5ce37471-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cc51818b96ee48a297ee196a5ce37471-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your e-commerce query\n",
    "query = \"case for iphone\"\n",
    "\n",
    "# Process the query\n",
    "doc = nlp(query)\n",
    "\n",
    "# Print dependency tree details\n",
    "print(f\"{'Token':<10} {'Dep':<10} {'Head':<10} {'POS':<10} {'Children'}\")\n",
    "print(\"-\" * 50)\n",
    "for token in doc:\n",
    "    children = [child.text for child in token.children]\n",
    "    print(f\"{token.text:<10} {token.dep_:<10} {token.head.text:<10} {token.pos_:<10} {children}\")\n",
    "\n",
    "# OPTIONAL: Visualize dependency tree (works in Jupyter or web contexts)\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2490777-b067-4e99-a4c5-b5c57dcff600",
   "metadata": {},
   "source": [
    "# POS Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c23fe0-d7d0-47aa-b376-7280ba488bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary main noun: phone\n",
      "Primary prev nouns: s24 galaxy\n",
      "Adj ref Primary noun: best\n",
      "ADP ref Primary noun: with\n",
      "Secondary main noun: 50\n",
      "Secondary prev nouns: N/A\n",
      "Adj ref Secondary noun: N/A\n",
      "ADP ref Secondary noun: N/A\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define connectors with grammar-based rules\n",
    "left_primary = {\"with\", \"for\", \"under\"}\n",
    "right_primary = { \"of\", \"to\", \"from\", \"about\", \"on\", \"by\"}\n",
    "\n",
    "def extract_info(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize outputs\n",
    "    primary = {\"main_noun\": \"\", \"prev_nouns\": \"\", \"adj\": \"\", \"adp\": \"\"}\n",
    "    secondary = {\"main_noun\": \"\", \"prev_nouns\": \"\", \"adj\": \"\", \"adp\": \"\"}\n",
    "\n",
    "    connector_token = None\n",
    "\n",
    "    # Step 1: Find the first relevant connector\n",
    "    for token in doc:\n",
    "        if token.text.lower() in left_primary.union(right_primary) and token.pos_ == \"ADP\":\n",
    "            connector_token = token\n",
    "            break\n",
    "\n",
    "    if connector_token:\n",
    "        # Process left side\n",
    "        left_tokens = list(doc[:connector_token.i])\n",
    "        left_main_noun, left_prev_nouns = \"\", \"\"\n",
    "        for i in reversed(range(len(left_tokens))):\n",
    "            token = left_tokens[i]\n",
    "            if token.pos_ in {\"NOUN\", \"PROPN\",\"NUM\"}:\n",
    "                left_main_noun = token.text\n",
    "                prev_nouns = []\n",
    "                for j in reversed(range(i)):\n",
    "                    if left_tokens[j].pos_ in {\"NOUN\", \"PROPN\",\"NUM\"}:\n",
    "                        prev_nouns.insert(0, left_tokens[j].text)\n",
    "                    else:\n",
    "                        break\n",
    "                left_prev_nouns = \" \".join(prev_nouns)\n",
    "                break\n",
    "\n",
    "        # Process right side\n",
    "        right_tokens = list(doc[connector_token.i + 1:])\n",
    "        right_main_noun, right_prev_nouns = \"\", \"\"\n",
    "        for i, token in enumerate(right_tokens):\n",
    "            if token.pos_ in {\"NOUN\", \"PROPN\",\"NUM\"}:\n",
    "                right_main_noun = token.text\n",
    "                prev_nouns = []\n",
    "                for j in reversed(range(i)):\n",
    "                    if right_tokens[j].pos_ in {\"NOUN\", \"PROPN\",\"NUM\"}:\n",
    "                        prev_nouns.insert(0, right_tokens[j].text)\n",
    "                    else:\n",
    "                        break\n",
    "                right_prev_nouns = \" \".join(prev_nouns)\n",
    "                break\n",
    "\n",
    "        connector = connector_token.text.lower()\n",
    "\n",
    "        # Assign primary and secondary based on connector\n",
    "        if connector in left_primary:\n",
    "            primary[\"main_noun\"] = left_main_noun\n",
    "            primary[\"prev_nouns\"] = left_prev_nouns\n",
    "            secondary[\"main_noun\"] = right_main_noun\n",
    "            secondary[\"prev_nouns\"] = right_prev_nouns\n",
    "        elif connector in right_primary:\n",
    "            primary[\"main_noun\"] = right_main_noun\n",
    "            primary[\"prev_nouns\"] = right_prev_nouns\n",
    "            secondary[\"main_noun\"] = left_main_noun\n",
    "            secondary[\"prev_nouns\"] = left_prev_nouns\n",
    "\n",
    "        # Step 2: Find adjectives, adpositions, referring to nouns\n",
    "        for token in doc:\n",
    "            if token.head.text == primary[\"main_noun\"]:\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    primary[\"adj\"] = token.text\n",
    "                if token.pos_ == \"ADP\":\n",
    "                    primary[\"adp\"] = token.text\n",
    "            if token.head.text == secondary[\"main_noun\"]:\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    secondary[\"adj\"] = token.text\n",
    "                if token.pos_ == \"ADP\":\n",
    "                    secondary[\"adp\"] = token.text\n",
    "\n",
    "    return {\n",
    "        \"Primary main noun\": primary[\"main_noun\"],\n",
    "        \"Primary prev nouns\": primary[\"prev_nouns\"],\n",
    "        \"Adj ref Primary noun\": primary[\"adj\"],\n",
    "        \"ADP ref Primary noun\": primary[\"adp\"],\n",
    "        \"Secondary main noun\": secondary[\"main_noun\"],\n",
    "        \"Secondary prev nouns\": secondary[\"prev_nouns\"],\n",
    "        \"Adj ref Secondary noun\": secondary[\"adj\"],\n",
    "        \"ADP ref Secondary noun\": secondary[\"adp\"],\n",
    "    }\n",
    "\n",
    "# Test Example\n",
    "text = \"best s24 galaxy phone with 50 mp camera\"\n",
    "result = extract_info(text)\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value if value else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3f39bad-7977-409a-b2b0-eee41c492d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary main noun: phone\n",
      "Primary prev nouns: N/A\n",
      "Adj ref Primary noun: cheap\n",
      "ADP ref Primary noun: for\n",
      "Secondary main noun: charger\n",
      "Secondary next nouns: N/A\n",
      "Adj ref Secondary noun: N/A\n",
      "ADP ref Secondary noun: N/A\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define connectors with grammar-based rules\n",
    "left_primary = {\"with\", \"for\", \"under\"}\n",
    "right_primary = { \"of\", \"to\", \"from\", \"about\", \"on\", \"by\"}\n",
    "\n",
    "noun_pos_tags = {\"NOUN\", \"PROPN\", \"NUM\"}\n",
    "\n",
    "def extract_info(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    primary = {\"main_noun\": \"\", \"prev_nouns\": \"\", \"adj\": \"\", \"adp\": \"\"}\n",
    "    secondary = {\"main_noun\": \"\", \"next_nouns\": \"\", \"adj\": \"\", \"adp\": \"\"}\n",
    "\n",
    "    connector_token = None\n",
    "\n",
    "    # Find connector\n",
    "    for token in doc:\n",
    "        if token.text.lower() in left_primary.union(right_primary) and token.pos_ == \"ADP\":\n",
    "            connector_token = token\n",
    "            break\n",
    "\n",
    "    if connector_token:\n",
    "        left_tokens = list(doc[:connector_token.i])\n",
    "        right_tokens = list(doc[connector_token.i + 1:])\n",
    "\n",
    "        left_main_noun, left_prev_nouns = \"\", \"\"\n",
    "        right_main_noun, right_next_nouns = \"\", \"\"\n",
    "\n",
    "        # Find left main noun & previous consecutive nouns\n",
    "        for i in reversed(range(len(left_tokens))):\n",
    "            token = left_tokens[i]\n",
    "            if token.pos_ in noun_pos_tags:\n",
    "                left_main_noun = token.text\n",
    "                prev_nouns = []\n",
    "                for j in reversed(range(i)):\n",
    "                    if left_tokens[j].pos_ in noun_pos_tags:\n",
    "                        prev_nouns.insert(0, left_tokens[j].text)\n",
    "                    else:\n",
    "                        break\n",
    "                left_prev_nouns = \" \".join(prev_nouns)\n",
    "                break\n",
    "\n",
    "        # Find right main noun & next consecutive nouns\n",
    "        for i, token in enumerate(right_tokens):\n",
    "            if token.pos_ in noun_pos_tags:\n",
    "                right_main_noun = token.text\n",
    "                next_nouns = []\n",
    "                for j in range(i + 1, len(right_tokens)):\n",
    "                    if right_tokens[j].pos_ in noun_pos_tags:\n",
    "                        next_nouns.append(right_tokens[j].text)\n",
    "                    else:\n",
    "                        break\n",
    "                right_next_nouns = \" \".join(next_nouns)\n",
    "                break\n",
    "\n",
    "        connector = connector_token.text.lower()\n",
    "\n",
    "        if connector in left_primary:\n",
    "            primary[\"main_noun\"] = left_main_noun\n",
    "            primary[\"prev_nouns\"] = left_prev_nouns\n",
    "            secondary[\"main_noun\"] = right_main_noun\n",
    "            secondary[\"next_nouns\"] = right_next_nouns\n",
    "        elif connector in right_primary:\n",
    "            primary[\"main_noun\"] = right_main_noun\n",
    "            primary[\"prev_nouns\"] = right_prev_nouns\n",
    "            secondary[\"main_noun\"] = left_main_noun\n",
    "            secondary[\"next_nouns\"] = left_prev_nouns\n",
    "\n",
    "        # Find adjectives, adpositions, verbs referring to nouns\n",
    "        for token in doc:\n",
    "            if token.head.text == primary[\"main_noun\"]:\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    primary[\"adj\"] = token.text\n",
    "                if token.pos_ == \"ADP\":\n",
    "                    primary[\"adp\"] = token.text\n",
    "\n",
    "            if token.head.text == secondary[\"main_noun\"]:\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    secondary[\"adj\"] = token.text\n",
    "                if token.pos_ == \"ADP\":\n",
    "                    secondary[\"adp\"] = token.text\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Primary main noun\": primary[\"main_noun\"],\n",
    "        \"Primary prev nouns\": primary[\"prev_nouns\"],\n",
    "        \"Adj ref Primary noun\": primary[\"adj\"],\n",
    "        \"ADP ref Primary noun\": primary[\"adp\"],\n",
    "        \"Secondary main noun\": secondary[\"main_noun\"],\n",
    "        \"Secondary next nouns\": secondary[\"next_nouns\"],\n",
    "        \"Adj ref Secondary noun\": secondary[\"adj\"],\n",
    "        \"ADP ref Secondary noun\": secondary[\"adp\"],\n",
    "    }\n",
    "\n",
    "# Test Example\n",
    "text = \"cheap phone with charger for gaming\"\n",
    "result = extract_info(text)\n",
    "\n",
    "# Pretty print\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value if value else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4a6b08-77d9-4e70-a248-054de46f9574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50 ground truth examples saved to 'generated_ground_truth_dataset.json'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "# Word banks\n",
    "nouns = [\"phone\", \"laptop\", \"charger\", \"headphones\", \"tablet\", \"watch\", \"camera\", \"speaker\", \"mic\", \"router\", \"printer\", \"monitor\", \"keyboard\", \"mouse\", \"projector\", \"powerbank\", \"case\", \"screen\", \"earbuds\", \"gamepad\"]\n",
    "adjs = [\"cheap\", \"fast\", \"wireless\", \"affordable\", \"powerful\", \"compatible\", \"new\", \"slim\", \"durable\", \"portable\", \"lightweight\", \"stylish\", \"reliable\", \"advanced\", \"smart\"]\n",
    "nums = [\"10000\", \"500\", \"65w\", \"256gb\", \"2tb\", \"50\", \"100\", \"2000\", \"300\", \"150\"]\n",
    "adps = [\"with\", \"for\", \"under\", \"above\", \"beside\", \"without\"]\n",
    "\n",
    "# 50 sentence templates\n",
    "templates = [\n",
    "    \"Give me {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"I want {noun1} for {adj2} {noun2}.\",\n",
    "    \"Find {adj1} {noun1} under {num}.\",\n",
    "    \"Looking for {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Buy {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Get {noun1} for {adj2} {noun2}.\",\n",
    "    \"Search {adj1} {noun1} under {num}.\",\n",
    "    \"Order {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Cheap {noun1} for {adj2} {noun2}.\",\n",
    "    \"Looking for {adj1} {noun1} above {num}.\",\n",
    "    \"I need {adj1} {noun1} beside {adj2} {noun2}.\",\n",
    "    \"Get {noun1} without {adj2} {noun2}.\",\n",
    "    \"Find {adj1} {noun1} above {num}.\",\n",
    "    \"Order {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"New {noun1} with {adj2} {noun2}.\",\n",
    "    \"Affordable {noun1} for {adj2} {noun2}.\",\n",
    "    \"Looking for {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Buy {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"Search for {adj1} {noun1} under {num}.\",\n",
    "    \"Get {adj1} {noun1} above {num}.\",\n",
    "    \"Order {adj1} {noun1} beside {adj2} {noun2}.\",\n",
    "    \"Find {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"Need {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Looking for {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"Cheap {adj1} {noun1} under {num}.\",\n",
    "    \"Buy {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Order {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"I want {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Need {adj1} {noun1} under {num}.\",\n",
    "    \"Searching for {adj1} {noun1} above {num}.\",\n",
    "    \"Purchase {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"Get {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Find {adj1} {noun1} beside {adj2} {noun2}.\",\n",
    "    \"Affordable {adj1} {noun1} above {num}.\",\n",
    "    \"New {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"Order {adj1} {noun1} under {num}.\",\n",
    "    \"Need {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Searching {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"Get {adj1} {noun1} under {num}.\",\n",
    "    \"Looking for {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"Purchase {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"I want {adj1} {noun1} above {num}.\",\n",
    "    \"Find {adj1} {noun1} beside {adj2} {noun2}.\",\n",
    "    \"Buy {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"Affordable {adj1} {noun1} with {adj2} {noun2}.\",\n",
    "    \"Order {adj1} {noun1} for {adj2} {noun2}.\",\n",
    "    \"Looking for {adj1} {noun1} beside {adj2} {noun2}.\",\n",
    "    \"Purchase {adj1} {noun1} above {num}.\",\n",
    "    \"Need {adj1} {noun1} without {adj2} {noun2}.\",\n",
    "    \"Cheap {adj1} {noun1} for {adj2} {noun2}.\"\n",
    "]\n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "for template in templates:\n",
    "    adj1 = random.choice(adjs)\n",
    "    adj2 = random.choice(adjs)\n",
    "    noun1 = random.choice(nouns)\n",
    "    noun2 = random.choice(nouns)\n",
    "    num = random.choice(nums)\n",
    "\n",
    "    sentence = template.format(adj1=adj1, adj2=adj2, noun1=noun1, noun2=noun2, num=num)\n",
    "\n",
    "    # Basic rule-based expected output logic\n",
    "    expected = {}\n",
    "\n",
    "    if \" with \" in template and \" for \" not in template:\n",
    "        expected = {\n",
    "            \"Primary main noun\": noun1,\n",
    "            \"Primary prev nouns\": \"\",\n",
    "            \"Adj ref Primary noun\": adj1,\n",
    "            \"ADP ref Primary noun\": \"\",\n",
    "            \"Verb ref Primary noun\": \"\",\n",
    "            \"Secondary main noun\": noun2,\n",
    "            \"Secondary next nouns\": \"\",\n",
    "            \"Adj ref Secondary noun\": adj2,\n",
    "            \"ADP ref Secondary noun\": \"\",\n",
    "            \"Verb ref Secondary noun\": \"\"\n",
    "        }\n",
    "    elif \" for \" in template:\n",
    "        expected = {\n",
    "            \"Primary main noun\": noun2,\n",
    "            \"Primary prev nouns\": \"\",\n",
    "            \"Adj ref Primary noun\": adj2,\n",
    "            \"ADP ref Primary noun\": \"\",\n",
    "            \"Verb ref Primary noun\": \"\",\n",
    "            \"Secondary main noun\": noun1,\n",
    "            \"Secondary next nouns\": \"\",\n",
    "            \"Adj ref Secondary noun\": adj1,\n",
    "            \"ADP ref Secondary noun\": \"\",\n",
    "            \"Verb ref Secondary noun\": \"\"\n",
    "        }\n",
    "    elif \" under \" in template or \" above \" in template:\n",
    "        adp = \"under\" if \" under \" in template else \"above\"\n",
    "        expected = {\n",
    "            \"Primary main noun\": noun1,\n",
    "            \"Primary prev nouns\": \"\",\n",
    "            \"Adj ref Primary noun\": adj1,\n",
    "            \"ADP ref Primary noun\": adp,\n",
    "            \"Verb ref Primary noun\": \"\",\n",
    "            \"Secondary main noun\": num,\n",
    "            \"Secondary next nouns\": \"\",\n",
    "            \"Adj ref Secondary noun\": \"\",\n",
    "            \"ADP ref Secondary noun\": \"\",\n",
    "            \"Verb ref Secondary noun\": \"\"\n",
    "        }\n",
    "    else:\n",
    "        expected = {\n",
    "            \"Primary main noun\": noun1,\n",
    "            \"Primary prev nouns\": \"\",\n",
    "            \"Adj ref Primary noun\": adj1,\n",
    "            \"ADP ref Primary noun\": \"\",\n",
    "            \"Verb ref Primary noun\": \"\",\n",
    "            \"Secondary main noun\": noun2,\n",
    "            \"Secondary next nouns\": \"\",\n",
    "            \"Adj ref Secondary noun\": adj2,\n",
    "            \"ADP ref Secondary noun\": \"\",\n",
    "            \"Verb ref Secondary noun\": \"\"\n",
    "        }\n",
    "\n",
    "    test_dataset.append({\n",
    "        \"text\": sentence,\n",
    "        \"expected\": expected\n",
    "    })\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"generated_ground_truth_dataset.json\", \"w\") as f:\n",
    "    json.dump(test_dataset, f, indent=4)\n",
    "\n",
    "print(\"Generated 50 ground truth examples saved to 'generated_ground_truth_dataset.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f9e20-e814-4924-91f5-2097481c7c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
